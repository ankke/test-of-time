{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark SF Energy Load dataset on multiple models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows how to create a simple benchmark with **multiple models** for the **SF Energy Load** datasets.\n",
    "Further, it investigates on the individual performance of the NeuralProphet model configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"google.colab\" in str(get_ipython()):\n",
    "    !pip install git+https://github.com/ourownstory/neural_prophet.git # may take a while\n",
    "    #!pip install neuralprophet # much faster, but may not have the latest upgrades/bugfixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tot.dataset import Dataset\n",
    "from tot.models_simple import LinearRegressionModel, ProphetModel\n",
    "from tot.models_neuralprophet import NeuralProphetModel, TorchProphetModel\n",
    "from tot.models_naive import SeasonalNaiveModel, NaiveModel\n",
    "from tot.benchmark import SimpleBenchmark\n",
    "from tot.plot_forecast_plotly import plot\n",
    "\n",
    "from neuralprophet import set_log_level\n",
    "\n",
    "from plotly_resampler import register_plotly_resampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_log_level(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot settings\n",
    "We use ``plotly`` for standard plotting and activate the plotly-resampler package to seamlessly\n",
    "display plots with large data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = 'plotly'\n",
    "register_plotly_resampler('figure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Manage data\n",
    "##### Load datasets\n",
    "We load the **SF Energy Load** datasets that we will use in the benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = \"https://raw.githubusercontent.com/ourownstory/neuralprophet-data/main/datasets/\"\n",
    "df_sf_load= pd.read_csv(data_location + \"energy/SF_hospital_load.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inspect dataset\n",
    "First, letÂ´s have a closer look at the datasets. The **SF Energy Load** dataset has a single time\n",
    "series with 8760 samples. It has hourly frequency, and a daily and weekly seasonality. It does not seem to have a clear\n",
    "trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data samples: 8760\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.lib.display.IFrame at 0x2171ca39e80>",
      "text/html": "\n        <iframe\n            width=\"100%\"\n            height=\"468\"\n            src=\"http://127.0.0.1:8050/\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('data samples:', df_sf_load.shape[0])\n",
    "df_sf_load[0:14*24].plot(x='ds', y='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up the simple benchmark with 6 models\n",
    "We offer a template for a simple benchmark that is filled with the selected dataset(s), model(s) and model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we input the ``df_sf_load``, the name, and the data's frequency to the ``dataset_list``.\n",
    "Ideally, we add all available information about the dataset, in this the hourly frequency ``freq=\"H\"``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_list = [\n",
    "    Dataset(df=df_sf_load, name=\"sf_load\", freq=\"H\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Configure common model hyperparameters\n",
    "We want to compare the selected models on the same prediction task. We define N_FORECAST = 3 for all models. Besides for\n",
    "Prophet and TorchProphet, which only offers 1-step predictions.\n",
    "For all NeuralProphet models (which includes TorchProphet) we set a common ``learning_rate`` and ``epochs``."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "N_FORECASTS = 3\n",
    "LR = 0.01\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Select models and individual model parameters\n",
    "In total, we compare 6 different models. For each model we define the relevant hyperparameters. The NeuralProphet model\n",
    "we compare among 3 different configurations. The most simple configuration of NeuralProphet has **no autoregression**\n",
    "enabled.\n",
    "The 2nd configuration has **autoregression** enabled. For the 3rd configuration we add a pre-defined number of\n",
    "**hidden layers**. For the Prophet model we implement the original version as well as the offered neuralprophet\n",
    "wrapper, i.e. TorchProphet.\n",
    "To ensure comparability, we set the same number of lags ``n_lags`` for all models hat rely on historic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "model_classes_and_params = [\n",
    "    (NeuralProphetModel, {\"n_forecasts\": N_FORECASTS, \"n_lags\": 24,\n",
    "                          \"daily_seasonality\": True, \"weekly_seasonality\": True, \"yearly_seasonality\": False,\n",
    "                          \"num_hidden_layers\": 1, \"d_hidden\": 64,\n",
    "                          \"n_changepoints\":0, \"growth\":'linear',\n",
    "                          \"learning_rate\": LR, \"epochs\": EPOCHS }),\n",
    "    (NeuralProphetModel, {\"n_forecasts\": N_FORECASTS, \"n_lags\": 24,\n",
    "                          \"daily_seasonality\": True, \"weekly_seasonality\": True, \"yearly_seasonality\": False,\n",
    "                           \"n_changepoints\":0, \"growth\":'linear',\n",
    "                          \"learning_rate\": LR, \"epochs\": EPOCHS}),\n",
    "    (NeuralProphetModel, {\"n_forecasts\": 1,\n",
    "                          \"daily_seasonality\": True, \"weekly_seasonality\": True, \"yearly_seasonality\": False,\n",
    "                          \"n_changepoints\":0, \"growth\":'linear',\n",
    "                          \"learning_rate\": LR, \"epochs\": EPOCHS}),\n",
    "    (ProphetModel, {\"daily_seasonality\": True, \"weekly_seasonality\": True, \"yearly_seasonality\": False }),\n",
    "    (TorchProphetModel, {'interval_width': 0,\n",
    "                         \"daily_seasonality\": True, \"weekly_seasonality\": True, \"yearly_seasonality\": False}),\n",
    "    (SeasonalNaiveModel, {\"n_forecasts\": N_FORECASTS, \"season_length\": 24}),\n",
    "    (NaiveModel, {\"n_forecasts\": N_FORECASTS}),\n",
    "    (LinearRegressionModel, {\"n_forecasts\": N_FORECASTS, \"lags\": 24, \"output_chunk_length\": N_FORECASTS}),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Configure the benchmark\n",
    "Now, we add the dataset and the configured models to the SimpleBenchmark template to instantiate a benchmark. We select\n",
    "to return the MAPE error metric.\n",
    "Further error metrics can be added on demand. Further, we select the test data to be 40%."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "benchmark = SimpleBenchmark(\n",
    "    model_classes_and_params=model_classes_and_params,\n",
    "    datasets=dataset_list,\n",
    "    metrics=[\"MAPE\"],\n",
    "    test_percentage=0.4,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Besides the SimpleBenchmark class we offer further templates for pre-configured benchmarks as well as the option to\n",
    "manually configure a benchmark. For details, check the BenchmarkingTemplates.ipynb tutorial. We further offer various\n",
    "error metrics."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Run the benchmark\n",
    "We simply execute the benchmark by calling benchmark.run() and print the train and test results.\n",
    "To ensure reproducible results a seed is set within the procedure.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:01:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:01:40 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "text/plain": "Finding best initial lr:   0%|          | 0/243 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "372bcce748e54210a765d89ba5f86323"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5230 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "083ea88979b64b2d8c4fdfb9fff72356"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3502 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1b6e9e6c06d47e581a5ea1c1283f51a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_train, results_test = benchmark.run()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      data                  model  \\\n0  sf_load          NeuralProphet   \n1  sf_load          NeuralProphet   \n2  sf_load          NeuralProphet   \n3  sf_load                Prophet   \n4  sf_load           TorchProphet   \n5  sf_load          SeasonalNaive   \n6  sf_load             NaiveModel   \n7  sf_load  LinearRegressionModel   \n\n                                              params  \\\n0  {'n_forecasts': 3, 'n_lags': 24, 'daily_season...   \n1  {'n_forecasts': 3, 'n_lags': 24, 'daily_season...   \n2  {'n_forecasts': 1, 'daily_seasonality': True, ...   \n3  {'daily_seasonality': True, 'weekly_seasonalit...   \n4  {'interval_width': 0, 'daily_seasonality': Tru...   \n5  {'n_forecasts': 3, 'season_length': 24, '_data...   \n6  {'n_forecasts': 3, '_data_params': {'freq': 'H'}}   \n7  {'n_forecasts': 3, 'lags': 24, 'output_chunk_l...   \n\n                                          experiment      MAPE  \n0  sf_load_NeuralProphet_n_forecasts_3_n_lags_24_...  2.326252  \n1  sf_load_NeuralProphet_n_forecasts_3_n_lags_24_...  3.945043  \n2  sf_load_NeuralProphet_n_forecasts_1_daily_seas...  7.201104  \n3  sf_load_Prophet_daily_seasonality_True_weekly_...  7.358816  \n4  sf_load_TorchProphet_interval_width_0_daily_se...  7.647678  \n5  sf_load_SeasonalNaive_n_forecasts_3_season_len...  7.058735  \n6  sf_load_NaiveModel_n_forecasts_3__data_params_...  7.079551  \n7  sf_load_LinearRegressionModel_n_forecasts_3_la...  3.696180  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>data</th>\n      <th>model</th>\n      <th>params</th>\n      <th>experiment</th>\n      <th>MAPE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sf_load</td>\n      <td>NeuralProphet</td>\n      <td>{'n_forecasts': 3, 'n_lags': 24, 'daily_season...</td>\n      <td>sf_load_NeuralProphet_n_forecasts_3_n_lags_24_...</td>\n      <td>2.326252</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sf_load</td>\n      <td>NeuralProphet</td>\n      <td>{'n_forecasts': 3, 'n_lags': 24, 'daily_season...</td>\n      <td>sf_load_NeuralProphet_n_forecasts_3_n_lags_24_...</td>\n      <td>3.945043</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sf_load</td>\n      <td>NeuralProphet</td>\n      <td>{'n_forecasts': 1, 'daily_seasonality': True, ...</td>\n      <td>sf_load_NeuralProphet_n_forecasts_1_daily_seas...</td>\n      <td>7.201104</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sf_load</td>\n      <td>Prophet</td>\n      <td>{'daily_seasonality': True, 'weekly_seasonalit...</td>\n      <td>sf_load_Prophet_daily_seasonality_True_weekly_...</td>\n      <td>7.358816</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>sf_load</td>\n      <td>TorchProphet</td>\n      <td>{'interval_width': 0, 'daily_seasonality': Tru...</td>\n      <td>sf_load_TorchProphet_interval_width_0_daily_se...</td>\n      <td>7.647678</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>sf_load</td>\n      <td>SeasonalNaive</td>\n      <td>{'n_forecasts': 3, 'season_length': 24, '_data...</td>\n      <td>sf_load_SeasonalNaive_n_forecasts_3_season_len...</td>\n      <td>7.058735</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>sf_load</td>\n      <td>NaiveModel</td>\n      <td>{'n_forecasts': 3, '_data_params': {'freq': 'H'}}</td>\n      <td>sf_load_NaiveModel_n_forecasts_3__data_params_...</td>\n      <td>7.079551</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>sf_load</td>\n      <td>LinearRegressionModel</td>\n      <td>{'n_forecasts': 3, 'lags': 24, 'output_chunk_l...</td>\n      <td>sf_load_LinearRegressionModel_n_forecasts_3_la...</td>\n      <td>3.696180</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Let`s have a look at the individual results\n",
    "We plot and compare the forecasts of the test data of the NeuralProphet configurations.\n",
    "Since the **SF Energy Load** data has no clear trend, all configurations have  ``n_changpoints=0`` and ``growth='linear'``\n",
    "to predict one linear trend over the full train data range. Additionally, the ``daily_seasonality=True`` and\n",
    "``weekly_seasonality=True`` was set for all configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NeuralProphet Configuration 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NeuralProphet configuration 1  has not autoregression enabled and therefore ``n_forecast=1`` was set.\n",
    "To plot the results, we call the ``plot()`` function on the forecast. We can look up the experiment index of the\n",
    "respective forecast in the result table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE 7.201103687286377\n"
     ]
    }
   ],
   "source": [
    "print('MAPE',benchmark.df_metrics_test.loc[2,'MAPE'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.lib.display.IFrame at 0x2171b6ad7f0>",
      "text/html": "\n        <iframe\n            width=\"100%\"\n            height=\"418\"\n            src=\"http://127.0.0.1:8050/\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fcst_config1 = benchmark.fcst_test[2]\n",
    "fig = plot(fcst_config1)\n",
    "fig"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NeuralProphet Configuration 2\n",
    "For NeuralProphet configuration 2 autoregression with ``n_lags=24`` was added which is equal to 24h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE 3.9450433254241943\n"
     ]
    }
   ],
   "source": [
    "print('MAPE',benchmark.df_metrics_test.loc[1,'MAPE'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.lib.display.IFrame at 0x2171c9aa7c0>",
      "text/html": "\n        <iframe\n            width=\"100%\"\n            height=\"418\"\n            src=\"http://127.0.0.1:8050/\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fcst_config2 = benchmark.fcst_test[1]\n",
    "fig = plot(fcst_config2)\n",
    "fig"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### NeuralProphet Configuration 3\n",
    "For NeuralProphet configuration 3 one hidden layer ``num_hidden_layers=1`` with ``d_hidden=64`` was added."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE 2.326251983642578\n"
     ]
    }
   ],
   "source": [
    "print('MAPE',benchmark.df_metrics_test.loc[0,'MAPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.lib.display.IFrame at 0x2171c5bcbe0>",
      "text/html": "\n        <iframe\n            width=\"100%\"\n            height=\"418\"\n            src=\"http://127.0.0.1:8050/\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fcst_config3 = benchmark.fcst_test[0]\n",
    "fig = plot(fcst_config3)\n",
    "fig"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Result discussion\n",
    "Comparing all models, the **NeuralProphet configuration 3** achieves the\n",
    "best results on the SF Energy Load data. The **NeuralProphet configuration 2** shows a performance close\n",
    "to that. Hence, we can conclude that autoregression is essential to perform well on predicting the\n",
    "future data. Adding a hidden layer to the model benefits the performance further. The individual\n",
    "shapes of the data are predicted better in this case.\n",
    "Models without autoregressive capabilities perform comparatively worse. Except the performance of\n",
    "the **LinearRegression** is close to the models with autoregressive capabilities.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
