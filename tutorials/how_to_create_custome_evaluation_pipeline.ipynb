{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ourownstory/neural_prophet/blob/master/tutorials/UnderstandeTheBenchmarkingPipeline.ipynb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# How to create a custom evaluation pipeline\n",
    "This tutorial takes you behind the scenes of the benchmark template and guides you in creating your custom evaluation\n",
    "pipeline by explaining the processing step-by-step.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    !pip install git+https://github.com/ourownstory/test-of-time.git # may take a while\n",
    "    #!pip install test-of-time # much faster, but may not have the latest upgrades/bugfixes\n",
    "\n",
    "import pandas as pd\n",
    "from neuralprophet import set_log_level, set_random_seed\n",
    "from tot.df_utils import _check_min_df_len, prep_or_copy_df, check_dataframe, handle_missing_data, split_df, return_df_in_original_format, maybe_drop_added_dates\n",
    "from tot.exp_utils import evaluate_forecast\n",
    "from tot.models_neuralprophet import NeuralProphetModel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "set_log_level(\"ERROR\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The benchmark templates test-of-time offers are a quick and simple way to compare multiple models and datasets.\n",
    "Defining a benchmark and running it will trigger a pipeline that returns the benchmark results. The benchmark\n",
    "is sub-divided into multiple experiments, that are executed in the pipeline. Every experiment run follows the\n",
    "same evaluation steps. Let's have a closer look at the individual steps."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation processing steps\n",
    "1. Data-specific pre-processing:\n",
    "    Remark: This processing is independent of the model and specific to the data)\n",
    "    - Prepare dataframe to have an ID column\n",
    "    - Performs a basic sanity check\n",
    "    - Handles missing data\n",
    "    - Splits the data into train and test datasets\n",
    "\n",
    "2. Model definition\n",
    "    - Set random seed to ensure reproducibility\n",
    "    - define the model parameters\n",
    "    - instantiate your model\n",
    "\n",
    "3. Model-specific data pre-processing:\n",
    "    - Adjusts the data according to the model configuration to have each model be fitted and predicted correctly\n",
    "\n",
    "4. Fit model:\n",
    "    - Calls the fit method on the instantiated model object\n",
    "\n",
    "5. Predict model:\n",
    "    - Calls the predict method to create the forecast\n",
    "\n",
    "6. Model-specific data post-processing:\n",
    "    - Adjusts the data according to the model configuration to be returned consistently\n",
    "\n",
    "7. Data-specific post-processing:\n",
    "    - Drops any added dates\n",
    "\n",
    "8. Evaluation:\n",
    "    - Evaluates the forecasts based on selected error metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load data\n",
    "Let's load the AirPassenger dataset as an example dataset to walk through the pipeline step by step."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "data_location = \"https://raw.githubusercontent.com/ourownstory/neuralprophet-data/main/datasets/\"\n",
    "df_air = pd.read_csv(data_location + 'air_passengers.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Data-specific pre-processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# prep_or_copy_df() ensures that the df has an \"ID\" column to be usable in the further process\n",
    "df_air, received_ID_col, received_single_time_series, _ = prep_or_copy_df(df_air)\n",
    "# check_dataframe() performs a basic sanity check on the data\n",
    "df_air = check_dataframe(df_air, check_y=True)\n",
    "# handle_missing_data() imputes missing data\n",
    "df_air = handle_missing_data(df_air, freq='MS')\n",
    "# split_df() splits the data into train and test data\n",
    "df_air_train, df_air_test = split_df(\n",
    "    df=df_air,\n",
    "    test_percentage=0.40,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Model definition"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "set_random_seed(42)\n",
    "model_class = NeuralProphetModel\n",
    "params =  {\n",
    "    \"n_forecasts\": 3,\n",
    "    \"n_lags\":7,\n",
    "    \"seasonality_mode\": \"multiplicative\",\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"_data_params\":{},\n",
    "}\n",
    "model=model_class(params=params)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Model-specific data pre-processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# check if train and test df contain enough samples\n",
    "_check_min_df_len(df=df_air_train, min_len=model.n_forecasts + model.n_lags)\n",
    "_check_min_df_len(df=df_air_test, min_len=model.n_forecasts)\n",
    "# extend the test df with historic values from the train df\n",
    "df_air_test = model.maybe_extend_df(df_air_train, df_air_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Fit model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "model.model.fit(df=df_air_train, freq='MS', progress=\"none\", minimal=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Predict model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# the model-individual predict function outputs the forecasts as a df\n",
    "fcst_train = model.model.predict(df=df_air_train)\n",
    "fcst_test = model.model.predict(df=df_air_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6. Model-specific post-processing:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# As you can see, the method is a class method and hence linked to the model\n",
    "fcst_test, df_air_test = model.maybe_drop_added_values_from_df(fcst_test, df_air_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7. Data-specific data post-processing:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# in case an 'ID' column was previously added, return_df_in_original_format() will remove it again\n",
    "fcst_train_df = return_df_in_original_format(fcst_train, received_ID_col, received_single_time_series)\n",
    "fcst_test_df = return_df_in_original_format(fcst_test, received_ID_col, received_single_time_series)\n",
    "# in case, missing data was imputed maybe_drop_added_dates() removes it again\n",
    "fcst_train_df, df_air_train = maybe_drop_added_dates(fcst_train_df, df_air_train)\n",
    "fcst_test_df, df_air_test = maybe_drop_added_dates(fcst_test_df, df_air_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8. Evaluation:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MAPE': 8.895154, 'MAE': 37.84229, 'RMSE': 46.43487}\n"
     ]
    }
   ],
   "source": [
    "# evaluate_forecast() computes the selected error metrics\n",
    "result_train, result_test = evaluate_forecast(fcst_train_df, fcst_test_df, metrics=['MAPE','MAE','RMSE'], metadata=None)\n",
    "print(result_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
